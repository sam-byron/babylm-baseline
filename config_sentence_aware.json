{
  "block_size": 512,
  "batch_size": 24,
  "grad_accum": 3,
  "num_epochs": 25,
  "vocab_size": 16384,
  "dataset_split": "train",
  "learning_rate": 5e-05,
  "weight_decay": 0.05,
  "head_weight_decay": 0.005,
  "warmup_steps_proportion": 0.1,
  "checkpoint_path": "model_babylm_bert_ltg_checkpoint",
  "cache_path": "./model_babylm_bert_ltg_sentence_aware",
  "max_new_tokens": 400,
  "max_response_length": 150,
  "temperature": 0.9,
  "top_p": 0.8,
  "chunk_size": 40,
  "max_grad_norm": 1.5,
  "tokenizer_path": "./data/pretrain/wordpiece_vocab.json",
  "attention_probs_dropout_prob": 0.1,
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "intermediate_size": 2048,
  "position_bucket_size": 32,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "layer_norm_eps": 1e-05,
  "masking_strategy": "span",
  "mask_p": 0.15,
  "random_p": 0.1,
  "keep_p": 0.1,
  "use_dynamic_masking": true,
  "optimizer": "adamw",
  "share_layer_weights": true,
  "use_sentence_aware": true,
  "monitoring": {
    "spike_threshold": 0.3,
    "oscillation_threshold": 0.15,
    "window_size": 20
  }
}